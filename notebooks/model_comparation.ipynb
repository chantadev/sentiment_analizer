{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ccfc973",
   "metadata": {},
   "source": [
    "# Model Comparation \n",
    "This notebook is used for a comparation between 3 models: BERT, RoBERTa, DeepSeek. The model with the best metrics will be selected as the baseline for the application. I'll use Stanford Sentiment Treebank (SST-2) as the testing dataset. Although it's a binary dataset, the first iteration will be a 2-class classification: postive sentiments and negative sentiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803967b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# Set up HF token\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# The token is hardcoded here because is testing notebook, and may cause some issues if loaded with load_dotenv()\n",
    "HF_TOKEN=\"your_hf_token\"\n",
    "login(token=HF_TOKEN)\n",
    "\n",
    "# Reference: https://huggingface.co/datasets/cardiffnlp/tweet_eval\n",
    "dataset = load_dataset(\"glue\", \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "\n",
    "\n",
    "def train_evaluate_model(model: str):\n",
    "    \"\"\"\n",
    "    TODO: CREATE DOCUMENTATION\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model, num_labels=2)  # sst2 is a binary problem\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    save_name = model.split(\"/\")[-1]  # Standarize the model name\n",
    "\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"sentence\"],  \n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            max_length=256\n",
    "        )\n",
    "    \n",
    "    # Tokenize the dataset for the model\n",
    "    tokenized_dataset = dataset.map(\n",
    "        tokenize_function, \n",
    "        batched=True,\n",
    "        remove_columns=[\"sentence\", \"idx\"]  # Remove unnecesary data\n",
    "    )\n",
    "\n",
    "    # Split the dataset\n",
    "    train_dataset = tokenized_dataset[\"train\"]\n",
    "    val_dataset = tokenized_dataset[\"validation\"]\n",
    "    test_dataset = tokenized_dataset[\"test\"]\n",
    "\n",
    "    print(f\"   Train: {len(train_dataset)} samples\")\n",
    "    print(f\"   Val: {len(val_dataset)} samples\")\n",
    "    print(f\"   Test: {len(test_dataset)} samples\")\n",
    "\n",
    "    output_dir = f\"./results/{save_name}\"\n",
    "    model_save_dir = f\"./models/{save_name}\"\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=3,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=32,\n",
    "            learning_rate=2e-5,\n",
    "            \n",
    "            # Evaluation and best saving\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"eval_loss\",\n",
    "        )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer \n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # Check directory\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    trainer.save_model(model_save_dir)\n",
    "    print(f\"Model saved in: {model_save_dir}\")\n",
    "\n",
    "    # Save metrics\n",
    "    eval_results = trainer.evaluate()\n",
    "    with open(f\"{model_save_dir}/eval_results.txt\", \"w\") as f:\n",
    "        for key, value in eval_results.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "    # We'll only save the toknize dataset and the model\n",
    "    # We can add other parameters, but for a simple comparation it's not necessary\n",
    "    return {\n",
    "        'model': model,\n",
    "        'datasets': {\n",
    "            'train': train_dataset,\n",
    "            'val': val_dataset, \n",
    "            'test': test_dataset\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ebebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta = train_evaluate_model(\"microsoft/deberta-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6216065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = train_evaluate_model(\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4484d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = train_evaluate_model(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_analizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
